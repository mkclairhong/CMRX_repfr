{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8671d-b7a3-4b47-b2aa-8c6bbd9f81c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp datasets\n",
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f0856-358b-48bf-9046-ec2c133ec7eb",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d58a1f-ca6f-4a48-9dac-d1e1a08b870d",
   "metadata": {},
   "source": [
    "Whether working with simulated data or the real deal, it has to be represented in a standardized way to enable interchangeable use of library functions.\n",
    "\n",
    "In general, we prepare data in two formats:\n",
    "\n",
    "- **Psifr-Format**. We use or modify code from the Psifr library for analysis of free recall data. Documentation of the data format expected by the library is provided in detail [here](https://psifr.readthedocs.io/en/latest/guide/import.html). In particular, our data preparation code tends to import data as specified in the linked documentation and then apply `psifr.merge_free_recall` to the imported DataFrame to enable direct computation of key summary statistics using other functions in the library.\n",
    "\n",
    "- **Trials Array**. The dataframes used by Psifr to prepare visualizes are useful for that purpose, but aren't ideal for the numerical calculations that often underlie tasks like model fitting. In prepared `trials` arrays, each row corresponds to a unique trial that some subject performed for the study, while each entry corresponds to a recall event. Each positive integer refers to a unique item within the context of that trial, while 0 can be safely coded as recall termination, and negative integers track unique intrusions (though we normally exclude those during data preparation).\n",
    "\n",
    "Our data preparation functions also tend to output associated metadata - e.g. list lengths, subject indices, condition vectors, and so on - useful for ensuring the correctness or speed of functions using them, or just for selecting subsets of the dataset for individualized analysis. I tend to add these in a haphazard way - when I realize I might use them! By including them in a dataset's associated preparation function, I avoid having to reimplement an extraction routine myself later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e1e3b-e552-41d6-84f5-fc53a8128945",
   "metadata": {},
   "source": [
    "## Murdock1962 Dataset\n",
    "This dataset doesn't have any item repetitions, but could be useful for sanity checks and whatnot.\n",
    "\n",
    "Our data structure associated with Murdock (1962) has three `LL` structures that each seem to correspond to a different data set with different list lengths.  Inside\n",
    "each structure is:\n",
    "- `recalls` with 1200 rows and 50 columns. Each row presumably represents a subject, and each column seems to\n",
    "  correspond to a recall position, with -1 coded for intrusions. `MurdData_clean.mat` probably doesn't have these\n",
    "  intrusions coded at all.\n",
    "- `listlength` is an integer indicating how long the studied list is.\n",
    "- `subject` is a 1200x1 vector coding the identities of each subject for each row. Each subject seems to get 80 rows a\n",
    "  piece. He really got that much data for each subject?\n",
    "- `session` similarly codes the index of the session under consideration, and it's always 1 in this case.\n",
    "- `presitemnumbers` probably codes the number associated with each item. Is just its presentation index.\n",
    "\n",
    "We'll enable selection of relevant information from these structures based on which `LL` structure we're interested in using a `dataset_index` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab5b84f-0934-4978-8be1-5f6800c9a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from psifr import fr\n",
    "\n",
    "def prepare_murddata(path, dataset_index):\n",
    "    \"\"\"\n",
    "    Prepares data formatted like `data/MurdData_clean.mat` for fitting.\n",
    "\n",
    "    Loads data from `path` with same format as `data/MurdData_clean.mat` and\n",
    "    returns a selected dataset as an array of unique recall trials and a\n",
    "    dataframe of unique study and recall events organized according to `psifr`\n",
    "    specifications.\n",
    "\n",
    "    **Arguments**:\n",
    "    - path: source of data file\n",
    "    - dataset_index: index of the dataset to be extracted from the file\n",
    "\n",
    "    **Returns**:\n",
    "    - trials: int64-array where rows identify a unique trial of responses and\n",
    "        columns corresponds to a unique recall index.\n",
    "    - merged: as a long format table where each row describes one study or\n",
    "        recall event.\n",
    "    - list_length: length of lists studied in the considered dataset\n",
    "    \"\"\"\n",
    "    # load all the data\n",
    "    matfile = sio.loadmat(path, squeeze_me=True)\n",
    "    murd_data = [matfile['data'].item()[0][i].item() for i in range(3)]\n",
    "\n",
    "    # encode dataset into psifr format\n",
    "    trials, list_length, subjects = murd_data[dataset_index][:3]\n",
    "    trials = trials.astype('int64')\n",
    "\n",
    "    data = []\n",
    "    for trial_index, trial in enumerate(trials):\n",
    "\n",
    "        # every time the subject changes, reset list_index\n",
    "        if not data or data[-1][0] != subjects[trial_index]:\n",
    "            list_index = 0\n",
    "        list_index += 1\n",
    "\n",
    "        # add study events\n",
    "        for i in range(list_length):\n",
    "            data += [[subjects[trial_index],\n",
    "                      list_index, 'study', i+1, i+1]]\n",
    "\n",
    "        # add recall events\n",
    "        for recall_index, recall_event in enumerate(trial):\n",
    "            if recall_event != 0:\n",
    "                data += [[subjects[trial_index], list_index,\n",
    "                          'recall', recall_index+1, recall_event]]\n",
    "\n",
    "    data = pd.DataFrame(data, columns=[\n",
    "        'subject', 'list', 'trial_type', 'position', 'item'])\n",
    "    merged = fr.merge_free_recall(data)\n",
    "    return trials, merged, list_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e449a74a-fbbe-4fe0-9bda-d64f8ad73fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "murd_trials, murd_events, murd_length = prepare_murddata(\n",
    "    '../../data/MurdData_clean.mat', 0)\n",
    "\n",
    "murd_events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b51391-cd62-4d25-96da-2bac131fabb3",
   "metadata": {},
   "source": [
    "## Lohnas2014 Dataset\n",
    "> Siegel, L. L., & Kahana, M. J. (2014). A retrieved context account of spacing and repetition effects in free recall. Journal of Experimental Psychology: Learning, Memory, and Cognition, 40(3), 755."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931c86e6-7171-487c-a477-d836756de187",
   "metadata": {},
   "source": [
    "Across 4 sessions, 35 subjects performed delayed free recall of 48 lists. Subjects were University of Pennsylvania undergraduates, graduates and staff, age 18-32. List items were drawn from a pool of 1638 words taken from the University of South Florida free association norms (Nelson, McEvoy, & Schreiber, 2004; Steyvers, Shiffrin, & Nelson, 2004, available at http://memory.psych.upenn.edu/files/wordpools/PEERS_wordpool.zip). Within each session, words were drawn without replacement. Words could repeat across sessions so long as they did not repeat in two successive sessions. Words were also selected to ensure that no strong semantic associates co-occurred in a given list (i.e., the semantic relatedness between any two words on a given list, as determined using WAS (Steyvers et al., 2004), did not exceed a threshold value of 0.55).\n",
    "\n",
    "Subjects encountered four different types of lists: \n",
    "1. Control lists that contained all once-presented items;  \n",
    "2. pure massed lists containing all twice-presented items; \n",
    "3. pure spaced lists consisting of items presented twice at lags 1-8, where lag is defined as the number of intervening items between a repeated item's presentations; \n",
    "4. mixed lists consisting of once presented, massed and spaced items. Within each session, subjects encountered three lists of each of these four types. \n",
    "\n",
    "In each list there were 40 presentation positions, such that in the control lists each position was occupied by a unique list item, and in the pure massed and pure spaced lists, 20 unique words were presented twice to occupy the 40 positions. In the mixed lists 28 once-presented and six twice-presented words occupied the 40 positions. In the pure spaced lists, spacings of repeated items were chosen so that each of the lags 1-8 occurred with equal probability. In the mixed lists, massed repetitions (lag=0) and spaced repetitions (lags 1-8) were chosen such that each of the 9 lags of 0-8 were used exactly twice within each session. The order of presentation for the different list types was randomized within each session. For the first session, the first four lists were chosen so that each list type was presented exactly once. An experimenter sat in with the subject for these first four lists, though no subject had difficulty understanding the task.\n",
    "\n",
    "The data for this experiment is stored in `data/repFR.mat`. We define a unique `prepare_repetition_data` function to build structures from the dataset that works with our existing data analysis and fitting functions.\n",
    "\n",
    "Like in `prepare_murd_data`, we need list lengths, a data frame for visualizations with psifir, and a trials array encoding recall events as sequences of presentation positions. But we'll also need an additional array tracking presentation order, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3733adae-ee0d-4f89-bc0e-434a34d10675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from psifr import fr\n",
    "\n",
    "def prepare_repdata(path):\n",
    "    \"\"\"\n",
    "    Prepares data formatted like `data/repFR.mat` for fitting.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load all the data\n",
    "    matfile = sio.loadmat(path, squeeze_me=True)['data'].item()\n",
    "    subjects = matfile[0]\n",
    "    pres_itemnos = matfile[4]\n",
    "    recalls = matfile[6]\n",
    "    list_types = matfile[7]\n",
    "    list_length = matfile[12]\n",
    "    \n",
    "    # convert pres_itemnos into rows of unique indices for easier model encoding\n",
    "    presentations = []\n",
    "    for i in range(len(pres_itemnos)):\n",
    "        seen = []\n",
    "        presentations.append([])\n",
    "        for p in pres_itemnos[i]:\n",
    "            if p not in seen:\n",
    "                seen.append(p)\n",
    "            presentations[-1].append(seen.index(p))\n",
    "    presentations = np.array(presentations)\n",
    "\n",
    "    # discard intrusions from recalls\n",
    "    trials = []\n",
    "    for i in range(len(recalls)):\n",
    "        trials.append([])\n",
    "        \n",
    "        trial = list(recalls[i])\n",
    "        for t in trial:\n",
    "            if (t > 0) and (t not in trials[-1]):\n",
    "                trials[-1].append(t)\n",
    "        \n",
    "        while len(trials[-1]) < list_length:\n",
    "            trials[-1].append(0)\n",
    "            \n",
    "    trials = np.array(trials)\n",
    "    \n",
    "    # encode dataset into psifr format\n",
    "    data = []\n",
    "    for trial_index, trial in enumerate(trials):\n",
    "        presentation = presentations[trial_index]\n",
    "        \n",
    "        # every time the subject changes, reset list_index\n",
    "        if not data or data[-1][0] != subjects[trial_index]:\n",
    "            list_index = 0\n",
    "        list_index += 1\n",
    "        \n",
    "        # add study events\n",
    "        for presentation_index, presentation_event in enumerate(presentation):\n",
    "            data += [[subjects[trial_index], \n",
    "                      list_index, 'study', presentation_index+1, presentation_event,  list_types[trial_index]\n",
    "                     ]]\n",
    "            \n",
    "        # add recall events\n",
    "        for recall_index, recall_event in enumerate(trial):\n",
    "            if recall_event != 0:\n",
    "                data += [[subjects[trial_index], list_index, \n",
    "                          'recall', recall_index+1, presentation[recall_event-1], list_types[trial_index]\n",
    "                         ]]\n",
    "                \n",
    "    data = pd.DataFrame(data, columns=[\n",
    "        'subject', 'list', 'trial_type', 'position', 'item', 'condition'])\n",
    "    merged = fr.merge_free_recall(data, list_keys=['condition'])\n",
    "    \n",
    "    return trials, merged, list_length, presentations, list_types, data, subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af70263-f4f3-43b0-89ba-ac0ec6dbfebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>item</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>study</th>\n",
       "      <th>recall</th>\n",
       "      <th>repeat</th>\n",
       "      <th>intrusion</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  list  item  input  output  study  recall  repeat  intrusion  \\\n",
       "0        1     1     0      1     1.0   True    True       0      False   \n",
       "1        1     1     1      2     2.0   True    True       0      False   \n",
       "2        1     1     2      3     3.0   True    True       0      False   \n",
       "3        1     1     3      4     4.0   True    True       0      False   \n",
       "4        1     1     4      5     5.0   True    True       0      False   \n",
       "\n",
       "   condition  \n",
       "0          4  \n",
       "1          4  \n",
       "2          4  \n",
       "3          4  \n",
       "4          4  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials, events, list_length, presentations, list_types, rep_data, subjects = prepare_repdata(\n",
    "    'data/repFR.mat')\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc1ce0a-c77a-4093-a371-a7157a18a875",
   "metadata": {},
   "source": [
    "## Simulated Datasets\n",
    "The approach for creating simulated datasets is to initialize a model with specified parameters and experience sequences and then populate a psifr-formatted array with the outcomes of performing `free recall`. \n",
    "\n",
    "The `simulate_data` function below presumes each item is just presented once and that a model has already been initialized, and is better for quick baseline characterization of model performance. Datasets with item repetitions during presentation violate this premise; a more unique function is normally necessary for simulating these models in a performant way.\n",
    "\n",
    "Since model simulation this way has always directly led to visualization in work done so far, a corresponding `trials` array is not produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04265bd4-282c-4978-9313-2c74735be1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def simulate_data(model, experiment_count, first_recall_item=None):\n",
    "    \"\"\"\n",
    "    Initialize a model with specified parameters and experience sequences and \n",
    "    then populate a psifr-formatted dataframe with the outcomes of performing `free recall`. \n",
    "    \n",
    "    **Required model attributes**:\n",
    "    - item_count: specifies number of items encoded into memory\n",
    "    - context: vector representing an internal contextual state\n",
    "    - experience: adding a new trace to the memory model\n",
    "    - free_recall: function that freely recalls a given number of items or until recall stops\n",
    "    \"\"\"\n",
    "    \n",
    "    # encode items\n",
    "    try:\n",
    "        model.experience(np.eye(model.item_count, model.item_count + 1, 1))\n",
    "    except ValueError:\n",
    "        # so we can apply to CMR\n",
    "        model.experience(np.eye(model.item_count, model.item_count))\n",
    "\n",
    "    # simulate retrieval for the specified number of times, tracking results in df\n",
    "    data = []\n",
    "    for experiment in range(experiment_count):\n",
    "        data += [[experiment, 0, 'study', i + 1, i] for i in range(model.item_count)]\n",
    "    for experiment in range(experiment_count):\n",
    "        if first_recall_item is not None:\n",
    "            model.force_recall(first_recall_item)\n",
    "        data += [[experiment, 0, 'recall', i + 1, o] for i, o in enumerate(model.free_recall())]\n",
    "    data = pd.DataFrame(data, columns=['subject', 'list', 'trial_type', 'position', 'item'])\n",
    "    merged = fr.merge_free_recall(data)\n",
    "    \n",
    "    return merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
